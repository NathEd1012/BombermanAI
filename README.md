In this project we developed and trained intelligent agents to play a version of the clas-
sical arcade game called Bomberman. In our approach, we used reinforcement learning
methods known as Q-learning and deep Q-learning. Key features were engineered to
reduce the dimensionality of the state space, including spatial awareness, path finding
and bomb avoidance mechanisms. We implemented metrics to evaluate agent perfor-
mance like survival rates, coin collection and bomb placements. In both models, our
training approach was to design and incrementally address scenarios of increasing dif-
ficulty, simplifying the learning process by breaking down the gameâ€™s complexities into
manageable steps. The final DQN model, which proved to be the better-performing one,
used a decaying epsilon-greedy policy and an experience replay in the training, achieving
effective gameplay in some of the considered scenarios.

<centering>
<img width="311" alt="Bomberman" src="https://github.com/user-attachments/assets/e4700335-45d9-4f13-a872-04ca10d74abd">

